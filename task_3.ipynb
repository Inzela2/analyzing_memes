{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlR0nZVrKZ8w",
        "outputId": "b9ccf3ec-8519-4fea-d236-7bc9204aad7d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcPCr0o1KSAh",
        "outputId": "ace86e6e-7f0d-4db7-b3fb-bc2e5fa12a94"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "----------\n",
            "train Loss: 0.7504 Acc: 0.6237\n",
            "val Loss: 0.4175 Acc: 0.8333\n",
            "Epoch 2/20\n",
            "----------\n",
            "train Loss: 0.5455 Acc: 0.7371\n",
            "val Loss: 0.2573 Acc: 0.9167\n",
            "Epoch 3/20\n",
            "----------\n",
            "train Loss: 0.5749 Acc: 0.7784\n",
            "val Loss: 0.3796 Acc: 0.8182\n",
            "Epoch 4/20\n",
            "----------\n",
            "train Loss: 0.6036 Acc: 0.7732\n",
            "val Loss: 0.2929 Acc: 0.9091\n",
            "Epoch 5/20\n",
            "----------\n",
            "train Loss: 0.4713 Acc: 0.7732\n",
            "val Loss: 0.2995 Acc: 0.8939\n",
            "Epoch 6/20\n",
            "----------\n",
            "train Loss: 0.3312 Acc: 0.8711\n",
            "val Loss: 0.2572 Acc: 0.9167\n",
            "Epoch 7/20\n",
            "----------\n",
            "train Loss: 0.3457 Acc: 0.8608\n",
            "val Loss: 0.2498 Acc: 0.9167\n",
            "Epoch 8/20\n",
            "----------\n",
            "train Loss: 0.5439 Acc: 0.8144\n",
            "val Loss: 0.2791 Acc: 0.9167\n",
            "Epoch 9/20\n",
            "----------\n",
            "train Loss: 0.3412 Acc: 0.8505\n",
            "val Loss: 0.3363 Acc: 0.8864\n",
            "Epoch 10/20\n",
            "----------\n",
            "train Loss: 0.6855 Acc: 0.7423\n",
            "val Loss: 0.5016 Acc: 0.8712\n",
            "Epoch 11/20\n",
            "----------\n",
            "train Loss: 0.6829 Acc: 0.7835\n",
            "val Loss: 0.7567 Acc: 0.8030\n",
            "Epoch 12/20\n",
            "----------\n",
            "train Loss: 0.4417 Acc: 0.8402\n",
            "val Loss: 0.4188 Acc: 0.8561\n",
            "Epoch 13/20\n",
            "----------\n",
            "train Loss: 0.4057 Acc: 0.8454\n",
            "val Loss: 0.2282 Acc: 0.9318\n",
            "Epoch 14/20\n",
            "----------\n",
            "train Loss: 0.2384 Acc: 0.8918\n",
            "val Loss: 0.2610 Acc: 0.8939\n",
            "Epoch 15/20\n",
            "----------\n",
            "train Loss: 0.4554 Acc: 0.8299\n",
            "val Loss: 0.3952 Acc: 0.8712\n",
            "Epoch 16/20\n",
            "----------\n",
            "train Loss: 0.5409 Acc: 0.8247\n",
            "val Loss: 0.2272 Acc: 0.9318\n",
            "Epoch 17/20\n",
            "----------\n",
            "train Loss: 0.4948 Acc: 0.8093\n",
            "val Loss: 0.2260 Acc: 0.9394\n",
            "Epoch 18/20\n",
            "----------\n",
            "train Loss: 0.4408 Acc: 0.8247\n",
            "val Loss: 0.3244 Acc: 0.9015\n",
            "Epoch 19/20\n",
            "----------\n",
            "train Loss: 0.4538 Acc: 0.8454\n",
            "val Loss: 0.3596 Acc: 0.8864\n",
            "Epoch 20/20\n",
            "----------\n",
            "train Loss: 0.4534 Acc: 0.8299\n",
            "val Loss: 0.2456 Acc: 0.9394\n",
            "Training complete\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "\n",
        "def get_img_paths(base_dir, folder_name):\n",
        "    folder_path = os.path.join(base_dir, folder_name)\n",
        "    img_paths = [os.path.join(folder_path, fname) for fname in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, fname))]\n",
        "    return img_paths\n",
        "\n",
        "base_dir = '/content/drive/My Drive'\n",
        "\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, class_to_idx, transform=None, test_mode=False):\n",
        "        self.img_paths = img_paths\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "        self.test_mode = test_mode\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_paths[index]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.test_mode:\n",
        "            return image, img_path\n",
        "        else:\n",
        "            label = self.class_to_idx[img_path.split('/')[-2]]\n",
        "            return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "class_to_idx = {'hate_meme': 0, 'not_meme': 1, 'test_meme': 0, 'test_not_meme': 1}\n",
        "\n",
        "train_dataset = CustomDataset(\n",
        "    img_paths=get_img_paths(base_dir, 'hate_meme') + get_img_paths(base_dir, 'not_meme'),\n",
        "    class_to_idx=class_to_idx,\n",
        "    transform=data_transforms['train']\n",
        ")\n",
        "\n",
        "val_dataset = CustomDataset(\n",
        "    img_paths=get_img_paths(base_dir, 'test_meme') + get_img_paths(base_dir, 'test_not_meme'),\n",
        "    class_to_idx=class_to_idx,\n",
        "    transform=data_transforms['val']\n",
        ")\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_dataset, batch_size=4, shuffle=True),\n",
        "    'val': DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "}\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 2)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "print('Training complete')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "not_meme_val_dataset = CustomDataset(\n",
        "    img_paths=get_img_paths(base_dir, 'test_not_meme'),\n",
        "    class_to_idx=class_to_idx,\n",
        "    transform=data_transforms['val']\n",
        ")\n",
        "\n",
        "hate_meme_val_dataset = CustomDataset(\n",
        "    img_paths=get_img_paths(base_dir, 'test_meme'),\n",
        "    class_to_idx=class_to_idx,\n",
        "    transform=data_transforms['val']\n",
        ")\n",
        "\n",
        "specific_val_dataset = not_meme_val_dataset + hate_meme_val_dataset\n",
        "\n",
        "specific_val_dataloader = DataLoader(specific_val_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "predicted_labels_specific = []\n",
        "true_labels_specific = []\n",
        "\n",
        "for inputs, labels in specific_val_dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "        predicted_labels_specific.extend(preds.cpu().numpy())\n",
        "        true_labels_specific.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "correct_predictions_specific = sum(p == t for p, t in zip(predicted_labels_specific, true_labels_specific))\n",
        "total_predictions_specific = len(predicted_labels_specific)\n",
        "accuracy_specific = correct_predictions_specific / total_predictions_specific\n",
        "\n",
        "print(f'Accuracy on specific dataset: {accuracy_specific:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc5VHhVrSUdd",
        "outputId": "54d2ff33-c7fd-4f2b-8e32-adc2d5fd3c84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on specific dataset: 0.9394\n"
          ]
        }
      ]
    }
  ]
}